{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot  as plt\n",
    "import numpy  as np\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "from gru_dataloader import GruDataLoader, collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return  '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A4ZPX2\n",
    "# tied1_name_l = ['Q5G5V8','Q5G5V4','Q6EG58','A4ZPW4','P04578','Q4QXE8','A8CVW4','Q2MKA8','A1EAH8','A1EAI4','Q27Q69','Q70014','B2YFU9','B2YFQ5','O89960']\n",
    "# # A1EAI3\n",
    "# tied2_name_l = ['Q5G5U7','Q5G5U5','A7KVY7','Q5G5V1','B0FBI6','Q5G5V5','A1EAI2','A1EAI0','Q6TCV7','Q202K1','Q202K7','Q27Q74','A1EAI7','B2YFT0','Q8JDI3']\n",
    "# # A4ZPW9\n",
    "# tied3_name_l = ['A4ZPX1','A4ZPW7','A4ZPW8','Q5G5V2','Q5G5U6','A1EAG8','A1EAH7','A0MTL0','A1EAH6','A1EAH3','B2YFP6','B2YFP1','B2YFU4','B2YFV4','B2YFS0']\n",
    "# tied_name=tied1_name_l+tied2_name_l+tied3_name_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(paths):\n",
    "    f=open(paths,\"r\")\n",
    "    seq_dict={}\n",
    "    for line in f:\n",
    "        if line.startswith('>'):\n",
    "                name=line.replace('>','').split()[0]\n",
    "                seq_dict[name]=''\n",
    "        else:\n",
    "                seq_dict[name]+=line.replace('\\n','').strip()\n",
    "    f.close()\n",
    "    return seq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datapath\n",
    "path1='/home/dldx/UniRep/datatmp/gp120_45/tier_1.fasta'\n",
    "path2='/home/dldx/UniRep/datatmp/gp120_45/tier_2.fasta'\n",
    "path3='/home/dldx/UniRep/datatmp/gp120_45/tier_3.fasta'\n",
    "\n",
    "path=[path1,path2,path3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_=[]\n",
    "type_=[]\n",
    "seqs_dict={}\n",
    "for i in range(3):\n",
    "    seq_dict=read_data(path[i])\n",
    "    seqs_dict.update(seq_dict)\n",
    "    seq=list(seq_dict.values())\n",
    "    seqs_+=seq\n",
    "    type_+=[i]*len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_train=seqs_\n",
    "type_train=type_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 45\n"
     ]
    }
   ],
   "source": [
    "print(len(seqs_train),len(type_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self,  is_train_set= True):\n",
    "        if is_train_set:\n",
    "            seqs = seqs_train    \n",
    "            types=type_train\n",
    "        else : \n",
    "            seqs = seqs_test    \n",
    "            types=type_test\n",
    "                \n",
    "        self.x_data = seqs\n",
    "        self.y_data = types\n",
    "\n",
    "        self.len = len(self.x_data)\n",
    "        \n",
    "        self.seqs_dict = seqs_dict\n",
    "        self.type_num = len(self.y_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #self.x_data[index], self.y_data[index]\n",
    "        #print('调用__getitem__')\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2list(seq):\n",
    "    arr = [ord(c)  for c  in seq]\n",
    "    return arr, len(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors(seqs, types):\n",
    "    sequences_and_lengths = [seq2list(seq)  for seq  in seqs]\n",
    "    name_sequences = [sl[0]  for sl  in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([sl[1]  for sl  in sequences_and_lengths])\n",
    "    types = types.long()\n",
    "    \n",
    "    # make tensor of name, BatchSize x SeqLen——>paddding\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    #print(len(seq_tensor[0]),type(seq_tensor[0]),seq_tensor[0].size(),seq_tensor[0])\n",
    "    \n",
    "    for idx, (seq, seq_len)  in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        #print('idx:',idx)\n",
    "        #print(seq,seq_len)\n",
    "        #x=torch.LongTensor(seq)\n",
    "       # print(x,type(x),x.size())\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "        \n",
    "    # sort by length to use pack_padded_sequence\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending= True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    types = types[perm_idx]\n",
    "    \n",
    "    return create_tensor(seq_tensor), \\\n",
    "            create_tensor(seq_lengths),\\\n",
    "            create_tensor(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers,attention_size, bidirectional= True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.layer_size=n_layers\n",
    "        self.n_directions = 2  if bidirectional  else 1\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                                bidirectional=bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)#torch.Size([64, 3])\n",
    "        \n",
    "\n",
    "        \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions,\n",
    "                             batch_size, self.hidden_size)\n",
    "        return create_tensor(hidden)\n",
    "    \n",
    "    \n",
    "    def forward(self, input, seq_lengths):\n",
    "        # input shape : B x S -> S x B\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        embedding = self.embedding(input)\n",
    "        \n",
    "        # pack them up\n",
    "        gru_input = torch.nn.utils.rnn.pack_padded_sequence(embedding, seq_lengths)\n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        #print(output[0].shape)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        #print(hidden_cat.shape)\n",
    "\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(classifier,train_loader):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (seqs, types)  in enumerate(train_loader, 1):\n",
    "        #print(types)\n",
    "        inputs, seq_lengths, target = make_tensors(seqs, types)\n",
    "        #print('seq_lengths',seq_lengths)\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        #print(\"inputs:\",inputs.size())\n",
    "        #print(\"output:\",output.size())\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total+=len(target)\n",
    "        pred = output.max(dim=1, keepdim= True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    percent =  '%.2f' % (100 * correct / total)\n",
    "    \n",
    "    total_loss += loss.item()\n",
    "#     if 0 == 0:\n",
    "#         print( f'loss={total_loss / (i *  len (inputs))}')\n",
    "    return total_loss,percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(classifier,train_loader):\n",
    "    classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    targets,outputs=[],[]\n",
    "    #print( \"evaluating trained model ...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (seqs, types)  in enumerate(train_loader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(seqs, types)\n",
    "\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "\n",
    "            pred = output.max(dim=1, keepdim= True)[1]\n",
    "            total+=len(target)\n",
    "\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            targets.append(target)\n",
    "            outputs.append(output)\n",
    "        percent =  '%.2f' % (100 * correct / total)\n",
    "#         print( f'Test set: Accuracy {correct}/{total} {percent}%')\n",
    "    classifier.train()\n",
    "    \n",
    "    return correct / total,outputs,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "HIDDEN_SIZE = 32\n",
    "BATCH_SIZE = 15\n",
    "N_LAYER = 2\n",
    "N_EPOCHS =100\n",
    "N_CHARS = 128\n",
    "USE_GPU =  True\n",
    "OUT_SIZE=3\n",
    "Attention_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# set up seeds, args.seed supported\n",
    "seed=2021\n",
    "torch.manual_seed(seed=seed)\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "#指定GPU\n",
    "torch.cuda.set_device(1)\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(seed=seed)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor(tensor):\n",
    "    if USE_GPU:\n",
    "        device = torch.device( \"cuda\")\n",
    "        tensor = tensor.to(device)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set : test_set = 40 : 5\n",
      "第0折完成,验证集准确率为0.8\n",
      "train_set : test_set = 40 : 5\n",
      "第1折完成,验证集准确率为0.4\n",
      "train_set : test_set = 40 : 5\n",
      "第2折完成,验证集准确率为0.8\n",
      "train_set : test_set = 40 : 5\n",
      "第3折完成,验证集准确率为0.6\n",
      "train_set : test_set = 40 : 5\n",
      "第4折完成,验证集准确率为0.6\n",
      "train_set : test_set = 41 : 4\n",
      "第5折完成,验证集准确率为0.5\n",
      "train_set : test_set = 41 : 4\n",
      "第6折完成,验证集准确率为0.75\n",
      "train_set : test_set = 41 : 4\n",
      "第7折完成,验证集准确率为0.5\n",
      "train_set : test_set = 41 : 4\n",
      "第8折完成,验证集准确率为0.5\n",
      "train_set : test_set = 41 : 4\n",
      "第9折完成,验证集准确率为0.5\n",
      "运行时间:299.96秒\n",
      "work down!\n"
     ]
    }
   ],
   "source": [
    "dataset=NameDataset(is_train_set= True)\n",
    "if USE_GPU:\n",
    "    device = torch.device( \"cuda\")\n",
    "\n",
    "train_l,test_l=[],[]\n",
    "datalist=[]\n",
    "draw_train=[]\n",
    "start = time.time()\n",
    "for fold_idx in range(10):\n",
    "    \n",
    "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, OUT_SIZE , N_LAYER,Attention_size).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loader,valid_loader = GruDataLoader(dataset, batch_size=45, device=device,\n",
    "                                                collate_fn=collate, seed=2021, shuffle=True,\n",
    "                                                split_name='fold10', fold_idx=fold_idx).train_valid_loader()\n",
    "    train_loss,draw_acc=[],[]\n",
    "    valid_acc_tmp=0\n",
    "    for epoch  in range(1, N_EPOCHS + 1):\n",
    "        # Train cycle\n",
    "    \n",
    "        los,_=trainModel(classifier,train_loader)\n",
    "\n",
    "        valid_acc,outputs,targets = testModel(classifier,valid_loader)\n",
    "        draw_acc.append(valid_acc)\n",
    "        train_loss.append(los)\n",
    "        if valid_acc > valid_acc_tmp:\n",
    "            valid_acc_tmp=valid_acc   \n",
    "    datalist.append([valid_acc_tmp,targets,outputs])\n",
    "    draw_train.append([train_loss,draw_acc])\n",
    "    print(\"第{}折完成,验证集准确率为{}\".format(fold_idx,valid_acc_tmp)) \n",
    "\n",
    "loss_acc='gru_acc_10fold_45.p'\n",
    "with open(loss_acc, 'wb') as f:\n",
    "    pickle.dump(datalist, f)\n",
    "end = time.time()\n",
    "print(\"运行时间:%.2f秒\"%(end-start))      \n",
    "print(\"work down!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_info=datalist\n",
    "\n",
    "acc=[]\n",
    "for i in range(10):\n",
    "    \n",
    "    acc.append(all_info[i][0])\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.135"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(draw_acc)\n",
    "plt.xlabel( 'Epoch')\n",
    "plt.ylabel( 'acc')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.xlabel( 'Epoch')\n",
    "plt.ylabel( 'acc')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.0969,  2.4106, -2.4007],\n",
       "         [ 0.5064,  0.5361, -1.3624],\n",
       "         [-2.0660, -0.6079,  3.0787],\n",
       "         [-1.1744,  2.3671, -2.3238],\n",
       "         [-0.6723,  1.1544, -1.1857]], device='cuda:1')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d2d780e36333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rocauc=[]\n",
    "AP=[]\n",
    "for k in range(10):\n",
    "    \n",
    "    score=(all_info[k][2][0].cpu().numpy())\n",
    "    label=(all_info[k][1][0].cpu().numpy())\n",
    "    label=label_binarize(label, classes=[0, 1, 2])\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    y_test,y_score=label,score\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    print(roc_auc[\"micro\"])\n",
    "    all_rocauc.append(roc_auc[\"micro\"])\n",
    "    #=========================================\n",
    "    Y_test,y_score=y_test,y_score\n",
    "    n_classes=3\n",
    "# For each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "        y_score.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(Y_test, y_score,\n",
    "                                                     average=\"micro\")\n",
    "    AP.append(average_precision[\"micro\"])\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "          .format(average_precision[\"micro\"]))\n",
    "print(np.mean(AP),np.std(AP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.6,0.3,0.56,0.24,0.4,0.75,0.84375,0.125,0.34375,0.625])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(all_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(AP),np.std(AP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='aqua',\n",
    "         lw=lw, label='ROC curve (AUC = %0.2f)' % roc_auc[2])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.02])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('ROC_all.png',format='png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "Y_test,y_score=y_test,y_score\n",
    "n_classes=3\n",
    "# For each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "    y_score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(Y_test, y_score,\n",
    "                                                     average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "      .format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.step(recall['micro'], precision['micro'], where='post')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\n",
    "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
    "    .format(average_precision[\"micro\"]))\n",
    "#plt.savefig('Average precision score.png',format='png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording the accuracy of testing.\n",
    "for i in range(10):\n",
    "    acc_list=train_l[i]\n",
    "    epoch = np.arange(1, len(acc_list) + 1, 1)\n",
    "    acc_list = np.array(acc_list)\n",
    "    plt.plot(epoch, acc_list)\n",
    "plt.xlabel( 'Epoch')\n",
    "plt.ylabel( 'Accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording the accuracy of testing.\n",
    "acc_max=[]\n",
    "for i in range(10):\n",
    "    acc_list=test_l[i]\n",
    "    acc_max.append(max(acc_list))\n",
    "\n",
    "    epoch = np.arange(1, len(acc_list) + 1, 1)\n",
    "    acc_list = np.array(acc_list)\n",
    "    plt.plot(epoch, acc_list)\n",
    "plt.xlabel( 'Epoch')\n",
    "plt.ylabel( 'Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(np.mean(acc_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (seqs, types)  in enumerate(train_loader, 1):\n",
    "    inputs, seq_lengths, target = make_tensors(seqs, types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Model(classifier):\n",
    "    classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print( \"evaluating trained model ...\")\n",
    "    with torch.no_grad():\n",
    "        for i, (seqs, types)  in enumerate(valid_loader, 1):\n",
    "            inputs, seq_lengths, target = make_tensors(seqs, types)\n",
    "\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "\n",
    "            pred = output.max(dim=1, keepdim= True)[1]\n",
    "            print(target)\n",
    "            total+=len(target)\n",
    "            \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        percent =  '%.2f' % (100 * correct / total)\n",
    "        print( f'Test set: Accuracy {correct}/{total} {percent}%')\n",
    "    classifier.train()\n",
    "    \n",
    "    return correct / total\n",
    "test_Model(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording the accuracy of testing.\n",
    "epoch = np.arange(1, len(losses) + 1, 1)\n",
    "loss = np.array(losses)\n",
    "plt.plot(epoch, loss)\n",
    "plt.xlabel( 'Epoch')\n",
    "plt.ylabel( 'loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, inputs.cpu(), target.cpu())\n",
    "scores\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evalModel(classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('qq.txt','r') as f:\n",
    "    dd=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii=list(dd.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:md] *",
   "language": "python",
   "name": "conda-env-md-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
