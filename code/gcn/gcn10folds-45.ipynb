{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "sys.path.append('/home/dldx/UniRep/pipgcn')#sys.path.append('引用模块地址')\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from my_dataloader import GraphDataLoader, collate\r\n",
    "from tqdm import tqdm\r\n",
    "import random\r\n",
    "import os\r\n",
    "import time\r\n",
    "import scipy.sparse as sp\r\n",
    "import pickle\r\n",
    "import dgl\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch.nn.functional as F\r\n",
    "from dgl.nn.pytorch import GraphConv\r\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class Classifier(nn.Module):\r\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes):\r\n",
    "        super(Classifier, self).__init__()\r\n",
    "        self.conv1 = GraphConv(in_dim, hidden_dim)\r\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\r\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\r\n",
    "\r\n",
    "    def forward(self, g,h):\r\n",
    "        # Use node degree as the initial node feature. For undirected graphs, the in-degree\r\n",
    "        # is the same as the out_degree.\r\n",
    "        #h = g.in_degrees().view(-1, 1).float()\r\n",
    "        # Perform graph convolution and activation function.\r\n",
    "        h = F.relu(self.conv1(g, h))\r\n",
    "        h = F.relu(self.conv2(g, h))\r\n",
    "        g.ndata['h'] = h\r\n",
    "        # Calculate graph representation by averaging all the node representations.\r\n",
    "        hg = dgl.sum_nodes(g, 'h')\r\n",
    "        return self.classify(hg)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# A4ZPX2\n",
    "tied1_name_l = ['Q5G5V8','Q5G5V4','Q6EG58','A4ZPW4','P04578','Q4QXE8','A8CVW4','Q2MKA8','A1EAH8','A1EAI4','Q27Q69','Q70014','B2YFU9','B2YFQ5','O89960']\n",
    "tied1_name_l.sort()\n",
    "# A1EAI3\n",
    "tied2_name_l = ['Q5G5U7','Q5G5U5','A7KVY7','Q5G5V1','B0FBI6','Q5G5V5','A1EAI2','A1EAI0','Q6TCV7','Q202K1','Q202K7','Q27Q74','A1EAI7','B2YFT0','Q8JDI3']\n",
    "tied2_name_l.sort()\n",
    "# A4ZPW9\n",
    "tied3_name_l = ['A4ZPX1','A4ZPW7','A4ZPW8','Q5G5V2','Q5G5U6','A1EAG8','A1EAH7','A0MTL0','A1EAH6','A1EAH3','B2YFP6','B2YFP1','B2YFU4','B2YFV4','B2YFS0']\n",
    "tied3_name_l.sort()\n",
    "tied_name=tied1_name_l+tied2_name_l+tied3_name_l\n",
    "with open(\"/home/dldx/UniRep/data/data45_true.p\", 'rb') as f:                      \n",
    "    dataset = pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#trainset.num_classes\n",
    "# set up seeds, args.seed supported\n",
    "import numpy as np\n",
    "seed=2021\n",
    "torch.manual_seed(seed=seed)\n",
    "np.random.seed(seed=seed)\n",
    "\n",
    "#指定GPU\n",
    "torch.cuda.set_device(1)\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(seed=seed)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "#device = torch.device(\"cpu\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# default collate function\n",
    "def collate1(samples):\n",
    "    # The input `samples` is a list of pairs (graph, label).\n",
    "    graphs, labels,_ = map(list, zip(*samples))\n",
    "    for g in graphs:\n",
    "        # deal with node feats\n",
    "        for key in g.node_attr_schemes().keys():\n",
    "            g.ndata[key] = g.ndata[key].float()\n",
    "        # no edge feats\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    labels = torch.tensor(labels)\n",
    "    return batched_graph, labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def train( net, trainloader, optimizer, criterion, epoch):\n",
    "    net.train()\n",
    "    running_loss = 0\n",
    "    total_iters = len(trainloader)\n",
    "\n",
    "    for graphs, labels in trainloader:\n",
    "        # batch graphs will be shipped to device in forward part of model\n",
    "        labels = labels.to(device)\n",
    "        #feat = graphs.ndata['attr'].to(device)\n",
    "        feat = graphs.ndata['feat'].float().to(device)\n",
    "        output = net(graphs, feat)\n",
    "#         outputs=output[0]\n",
    "        loss = criterion(output, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # the final batch will be aligned\n",
    "    running_loss = running_loss / total_iters\n",
    "\n",
    "    return running_loss \n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_net( net, dataloader, criterion):\n",
    "    net.eval()\n",
    "\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    targets,outputs=[],[]\n",
    "    for graphs, labels in dataloader:\n",
    "        feat = graphs.ndata['feat'].float().to(device)\n",
    "        labels = labels.to(device)\n",
    "        total += len(labels)\n",
    "        output = net(graphs, feat)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total_correct += (predicted == labels.data).sum().item()\n",
    "#         loss = criterion(output, labels)\n",
    "#         total_loss += loss.item() * len(labels)\n",
    "        targets.append(labels)\n",
    "        outputs.append(output)\n",
    "        acc = 1.0*total_correct / total\n",
    "        \n",
    "        \n",
    "    return acc,targets,outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#模型参数\n",
    "start = time.time()\n",
    "datalist=[]\n",
    "for fold_idx in range(10):\n",
    "    model =Classifier(17, 64, 3).to(device)\n",
    "    epochs=100\n",
    "    criterion = nn.CrossEntropyLoss()  # defaul reduce is true\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "    trainloader, validloader = GraphDataLoader(dataset, batch_size=45, device=device,\n",
    "                                                collate_fn=collate1, seed=2021, shuffle=True,\n",
    "                                                split_name='fold10', fold_idx=fold_idx).train_valid_loader()\n",
    "\n",
    "\n",
    "#     valid_accs,targets,outputs=[],[],[]\n",
    "    valid_acc_tmp=0\n",
    "    for epoch in range(epochs):\n",
    "        train( model, trainloader, optimizer, criterion, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "        \n",
    "#---------------------------动态输出训练结果-----------------------------     \n",
    "#         train_loss, train_acc = eval_net(model, trainloader, criterion)\n",
    "#         train_losses.append(train_loss)\n",
    "#         train_accs.append(train_acc)\n",
    "\n",
    "       \n",
    "        valid_acc,target,output = eval_net(model, validloader, criterion)\n",
    "        targets=target\n",
    "        outputs=output\n",
    "        if valid_acc > valid_acc_tmp:\n",
    "            valid_acc_tmp=valid_acc\n",
    "        \n",
    "    datalist.append([valid_acc_tmp,targets,outputs])\n",
    "    print(\"第{}折完成,验证集准确率为{}\".format(fold_idx,valid_acc_tmp)) \n",
    "    \n",
    "\n",
    "loss_acc='gcn_acc_10fold_45.p'\n",
    "with open(loss_acc, 'wb') as f:\n",
    "    pickle.dump(datalist, f)\n",
    "end = time.time()\n",
    "print(\"运行时间:%.2f秒\"%(end-start))      \n",
    "print(\"work down!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_set : test_set = 40 : 5\n",
      "第0折完成,验证集准确率为0.6\n",
      "train_set : test_set = 40 : 5\n",
      "第1折完成,验证集准确率为0.6\n",
      "train_set : test_set = 40 : 5\n",
      "第2折完成,验证集准确率为1.0\n",
      "train_set : test_set = 40 : 5\n",
      "第3折完成,验证集准确率为0.8\n",
      "train_set : test_set = 40 : 5\n",
      "第4折完成,验证集准确率为0.4\n",
      "train_set : test_set = 41 : 4\n",
      "第5折完成,验证集准确率为0.5\n",
      "train_set : test_set = 41 : 4\n",
      "第6折完成,验证集准确率为0.75\n",
      "train_set : test_set = 41 : 4\n",
      "第7折完成,验证集准确率为0.5\n",
      "train_set : test_set = 41 : 4\n",
      "第8折完成,验证集准确率为0.5\n",
      "train_set : test_set = 41 : 4\n",
      "第9折完成,验证集准确率为0.75\n",
      "运行时间:89.11秒\n",
      "work down!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#K folds result analyse\n",
    "\n",
    "loss_acc='gcn_acc_10fold_45.p'\n",
    "with open(loss_acc, 'rb') as f:\n",
    "    all_info=pickle.load(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "acc=[]\n",
    "for i in range(10):\n",
    "    acc.append(all_info[i][0])\n",
    "print(np.mean(acc))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "np.std(acc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.17291616465790582"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "acc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6, 0.6, 1.0, 0.8, 0.4, 0.5, 0.75, 0.5, 0.5, 0.75]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "all_rocauc=[]\n",
    "AP=[]\n",
    "for k in range(10):\n",
    "    \n",
    "    score=(all_info[k][2][0].cpu().numpy())\n",
    "    label=(all_info[k][1][0].cpu().numpy())\n",
    "    label=label_binarize(label, classes=[0, 1, 2])\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    y_test,y_score=label,score\n",
    "    for i in range(3):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    print(roc_auc[\"micro\"])\n",
    "    all_rocauc.append(roc_auc[\"micro\"])\n",
    "    #=========================================\n",
    "    Y_test,y_score=y_test,y_score\n",
    "    n_classes=3\n",
    "# For each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n",
    "\n",
    "    # A \"micro-average\": quantifying score on all classes jointly\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "        y_score.ravel())\n",
    "    average_precision[\"micro\"] = average_precision_score(Y_test, y_score,\n",
    "                                                     average=\"micro\")\n",
    "    AP.append(average_precision[\"micro\"])\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "          .format(average_precision[\"micro\"]))\n",
    "print(np.mean(AP),np.std(AP))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8200000000000001\n",
      "Average precision score, micro-averaged over all classes: 0.71\n",
      "0.56\n",
      "Average precision score, micro-averaged over all classes: 0.50\n",
      "0.8800000000000001\n",
      "Average precision score, micro-averaged over all classes: 0.80\n",
      "0.68\n",
      "Average precision score, micro-averaged over all classes: 0.58\n",
      "0.48\n",
      "Average precision score, micro-averaged over all classes: 0.41\n",
      "0.625\n",
      "Average precision score, micro-averaged over all classes: 0.50\n",
      "0.5\n",
      "Average precision score, micro-averaged over all classes: 0.40\n",
      "0.28125\n",
      "Average precision score, micro-averaged over all classes: 0.29\n",
      "0.375\n",
      "Average precision score, micro-averaged over all classes: 0.32\n",
      "0.625\n",
      "Average precision score, micro-averaged over all classes: 0.49\n",
      "0.49922383172383167 0.15239209438945683\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "np.std(all_rocauc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1759709226690592"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "np.mean(all_rocauc)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.582625"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_acc=[]\n",
    "valid_acc=[]\n",
    "for i in range(100):\n",
    "    d=data[i*2+1].split()\n",
    "    train_acc.append(float(d[1]))\n",
    "    valid_acc.append(float(d[3]))  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(valid_acc))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(train_acc, color='cornflowerblue')\n",
    "plt.plot(valid_acc, color='darkorange')\n",
    "labels=['train_acc','valid_acc']\n",
    "#plt.xlim([0, 50])\n",
    "#plt.ylim([0, 1])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.title('Train_acc vs Valid_acc')\n",
    "plt.legend(labels,loc=\"lower right\")\n",
    "plt.savefig('T_V.png',format='png',dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:md] *",
   "language": "python",
   "name": "conda-env-md-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}